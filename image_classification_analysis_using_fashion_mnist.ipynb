{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0497514a",
      "metadata": {
        "id": "0497514a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import defaultdict\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3931c8b7",
      "metadata": {
        "id": "3931c8b7"
      },
      "outputs": [],
      "source": [
        "# datasets\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Grayscale(),                    # Convert to grayscale\n",
        "    transforms.Resize((28, 28)),               # Resize to 28x28\n",
        "    transforms.ToTensor(),                     # Convert to tensor and normalize\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transforms)\n",
        "testset = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transforms)\n",
        "\n",
        "# constant for classes\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1c92c0",
      "metadata": {
        "id": "df1c92c0"
      },
      "source": [
        "# For single FC NN\n",
        "Input 784 x 1 \\\n",
        "Hidden layer: W 1024 x 784, b 1024 x 1 \\\n",
        "Output 10 x 1\n",
        "\n",
        "# For 2 FC NN\n",
        "Input 784 x 1 \\\n",
        "Hidden layer 1: W1 1024 x 784, b1 1024 x 1 \\\n",
        "Hidden layer 2: W2 1024 x 1024, b2 1024 x 1 \\\n",
        "Output layer W3 10 x 1024, b3 10 x 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21dc5110",
      "metadata": {
        "id": "21dc5110"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de6d2d9",
      "metadata": {
        "id": "2de6d2d9"
      },
      "outputs": [],
      "source": [
        "# Model with 1 Fully Connected Layer\n",
        "class SingleFCLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SingleFCLayer, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 1024)  # Input -> Hidden\n",
        "        self.fc2 = nn.Linear(1024, 10)  # Hidden -> Output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten 28x28 input\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3e175c",
      "metadata": {
        "id": "3c3e175c"
      },
      "outputs": [],
      "source": [
        "# Training and Evaluation Function\n",
        "def train_and_evaluate(model, batch_size, learning_rate, activation, epochs, trainset, testset):\n",
        "    # dataloaders\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "    # Initialize Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        train_loss = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_accuracy = correct_train / total_train * 100\n",
        "\n",
        "        # Validation/Test phase\n",
        "        model.eval()\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Track accuracy\n",
        "                _, predicted = outputs.max(1)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "                total_test += labels.size(0)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "        test_accuracy = correct_test / total_test * 100\n",
        "\n",
        "        print(f\"Epoch {epoch+1}:\",\n",
        "              f\"Train Accuracy: {train_accuracy:.2f}% | Test Accuracy: {test_accuracy:.2f}%\",\n",
        "              f\"Train Loss: {train_loss / len(trainloader):.4f} | Test Loss: {test_loss / len(testloader):.4f}\")\n",
        "\n",
        "    print(f\"Batch Size: {batch_size}, Learning Rate: {learning_rate}, Activation: {activation}, Final Train Accuracy: {train_accuracy:.2f}%, Final Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    return model, train_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db907c5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db907c5a",
        "outputId": "8daa1734-d594-400e-e81d-5a11a7109be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Accuracy: 58.42% | Test Accuracy: 65.38% Train Loss: 1.6754 | Test Loss: 1.2383\n",
            "Epoch 2: Train Accuracy: 68.12% | Test Accuracy: 68.85% Train Loss: 1.0464 | Test Loss: 0.9344\n",
            "Epoch 3: Train Accuracy: 72.05% | Test Accuracy: 72.47% Train Loss: 0.8548 | Test Loss: 0.8155\n",
            "Epoch 4: Train Accuracy: 74.69% | Test Accuracy: 74.69% Train Loss: 0.7651 | Test Loss: 0.7504\n",
            "Epoch 5: Train Accuracy: 76.53% | Test Accuracy: 76.00% Train Loss: 0.7088 | Test Loss: 0.7035\n",
            "Epoch 6: Train Accuracy: 77.96% | Test Accuracy: 77.37% Train Loss: 0.6681 | Test Loss: 0.6688\n",
            "Epoch 7: Train Accuracy: 79.03% | Test Accuracy: 78.14% Train Loss: 0.6367 | Test Loss: 0.6423\n",
            "Epoch 8: Train Accuracy: 80.02% | Test Accuracy: 78.73% Train Loss: 0.6119 | Test Loss: 0.6198\n",
            "Epoch 9: Train Accuracy: 80.53% | Test Accuracy: 79.55% Train Loss: 0.5912 | Test Loss: 0.6020\n",
            "Epoch 10: Train Accuracy: 81.03% | Test Accuracy: 80.03% Train Loss: 0.5742 | Test Loss: 0.5876\n",
            "Epoch 11: Train Accuracy: 81.52% | Test Accuracy: 80.47% Train Loss: 0.5597 | Test Loss: 0.5749\n",
            "Epoch 12: Train Accuracy: 81.84% | Test Accuracy: 80.58% Train Loss: 0.5473 | Test Loss: 0.5640\n",
            "Epoch 13: Train Accuracy: 82.16% | Test Accuracy: 81.25% Train Loss: 0.5365 | Test Loss: 0.5538\n",
            "Epoch 14: Train Accuracy: 82.40% | Test Accuracy: 81.39% Train Loss: 0.5271 | Test Loss: 0.5463\n",
            "Epoch 15: Train Accuracy: 82.67% | Test Accuracy: 81.48% Train Loss: 0.5186 | Test Loss: 0.5392\n",
            "Epoch 16: Train Accuracy: 82.89% | Test Accuracy: 81.78% Train Loss: 0.5110 | Test Loss: 0.5320\n",
            "Epoch 17: Train Accuracy: 83.00% | Test Accuracy: 81.86% Train Loss: 0.5044 | Test Loss: 0.5273\n",
            "Epoch 18: Train Accuracy: 83.23% | Test Accuracy: 82.00% Train Loss: 0.4982 | Test Loss: 0.5205\n",
            "Epoch 19: Train Accuracy: 83.38% | Test Accuracy: 82.15% Train Loss: 0.4926 | Test Loss: 0.5151\n",
            "Epoch 20: Train Accuracy: 83.47% | Test Accuracy: 82.34% Train Loss: 0.4872 | Test Loss: 0.5105\n",
            "Epoch 21: Train Accuracy: 83.59% | Test Accuracy: 82.30% Train Loss: 0.4824 | Test Loss: 0.5068\n",
            "Epoch 22: Train Accuracy: 83.84% | Test Accuracy: 82.57% Train Loss: 0.4780 | Test Loss: 0.5025\n",
            "Epoch 23: Train Accuracy: 83.86% | Test Accuracy: 82.70% Train Loss: 0.4740 | Test Loss: 0.4992\n",
            "Epoch 24: Train Accuracy: 83.95% | Test Accuracy: 82.87% Train Loss: 0.4702 | Test Loss: 0.4952\n",
            "Epoch 25: Train Accuracy: 84.13% | Test Accuracy: 82.90% Train Loss: 0.4665 | Test Loss: 0.4927\n",
            "Epoch 26: Train Accuracy: 84.23% | Test Accuracy: 82.66% Train Loss: 0.4631 | Test Loss: 0.4909\n",
            "Epoch 27: Train Accuracy: 84.25% | Test Accuracy: 83.14% Train Loss: 0.4599 | Test Loss: 0.4866\n",
            "Epoch 28: Train Accuracy: 84.43% | Test Accuracy: 82.95% Train Loss: 0.4569 | Test Loss: 0.4847\n",
            "Epoch 29: Train Accuracy: 84.50% | Test Accuracy: 83.14% Train Loss: 0.4539 | Test Loss: 0.4816\n",
            "Epoch 30: Train Accuracy: 84.62% | Test Accuracy: 83.18% Train Loss: 0.4512 | Test Loss: 0.4789\n",
            "Batch Size: 30, Learning Rate: 0.001, Activation: relu, Final Train Accuracy: 84.62%, Final Test Accuracy: 83.18%\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "momentum = 0\n",
        "batch_size = 30\n",
        "epochs = 30\n",
        "activation = 'relu' # Can be 'relu' or 'sigmoid'\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "model = SingleFCLayer()\n",
        "\n",
        "# Call the training and evaluation function\n",
        "model, train_accuracy, test_accuracy = train_and_evaluate(model, batch_size, learning_rate, activation, epochs, trainset, testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaecad3c",
      "metadata": {
        "id": "eaecad3c"
      },
      "outputs": [],
      "source": [
        "# Model with 2 Fully Connected Layers\n",
        "class TwoFCLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoFCLayers, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 1024)  # Input -> Hidden1\n",
        "        self.fc2 = nn.Linear(1024, 1024)  # Hidden1 -> Hidden2\n",
        "        self.fc3 = nn.Linear(1024, 10)  # Hidden2 -> Output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten 28x28 input\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8887ff9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8887ff9",
        "outputId": "6dc68d3a-da2d-4108-9b13-c782671f2677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Accuracy: 49.76% | Test Accuracy: 57.42% Train Loss: 2.0553 | Test Loss: 1.7102\n",
            "Epoch 2: Train Accuracy: 63.85% | Test Accuracy: 65.23% Train Loss: 1.3517 | Test Loss: 1.1073\n",
            "Epoch 3: Train Accuracy: 67.57% | Test Accuracy: 67.78% Train Loss: 0.9753 | Test Loss: 0.8968\n",
            "Epoch 4: Train Accuracy: 70.90% | Test Accuracy: 70.50% Train Loss: 0.8283 | Test Loss: 0.7974\n",
            "Epoch 5: Train Accuracy: 73.64% | Test Accuracy: 73.69% Train Loss: 0.7503 | Test Loss: 0.7374\n",
            "Epoch 6: Train Accuracy: 75.80% | Test Accuracy: 75.57% Train Loss: 0.6977 | Test Loss: 0.6922\n",
            "Epoch 7: Train Accuracy: 77.51% | Test Accuracy: 77.43% Train Loss: 0.6573 | Test Loss: 0.6575\n",
            "Epoch 8: Train Accuracy: 78.90% | Test Accuracy: 77.85% Train Loss: 0.6245 | Test Loss: 0.6302\n",
            "Epoch 9: Train Accuracy: 79.88% | Test Accuracy: 79.21% Train Loss: 0.5974 | Test Loss: 0.6044\n",
            "Epoch 10: Train Accuracy: 80.58% | Test Accuracy: 79.59% Train Loss: 0.5749 | Test Loss: 0.5854\n",
            "Epoch 11: Train Accuracy: 81.23% | Test Accuracy: 80.36% Train Loss: 0.5560 | Test Loss: 0.5710\n",
            "Epoch 12: Train Accuracy: 81.67% | Test Accuracy: 80.67% Train Loss: 0.5403 | Test Loss: 0.5543\n",
            "Epoch 13: Train Accuracy: 82.13% | Test Accuracy: 81.43% Train Loss: 0.5269 | Test Loss: 0.5447\n",
            "Epoch 14: Train Accuracy: 82.45% | Test Accuracy: 81.19% Train Loss: 0.5154 | Test Loss: 0.5349\n",
            "Epoch 15: Train Accuracy: 82.71% | Test Accuracy: 81.69% Train Loss: 0.5054 | Test Loss: 0.5246\n",
            "Epoch 16: Train Accuracy: 83.00% | Test Accuracy: 81.75% Train Loss: 0.4964 | Test Loss: 0.5187\n",
            "Epoch 17: Train Accuracy: 83.20% | Test Accuracy: 82.09% Train Loss: 0.4887 | Test Loss: 0.5111\n",
            "Epoch 18: Train Accuracy: 83.46% | Test Accuracy: 81.80% Train Loss: 0.4820 | Test Loss: 0.5122\n",
            "Epoch 19: Train Accuracy: 83.52% | Test Accuracy: 82.50% Train Loss: 0.4756 | Test Loss: 0.4990\n",
            "Epoch 20: Train Accuracy: 83.78% | Test Accuracy: 82.47% Train Loss: 0.4699 | Test Loss: 0.4957\n",
            "Epoch 21: Train Accuracy: 83.94% | Test Accuracy: 82.70% Train Loss: 0.4649 | Test Loss: 0.4908\n",
            "Epoch 22: Train Accuracy: 84.00% | Test Accuracy: 82.79% Train Loss: 0.4600 | Test Loss: 0.4858\n",
            "Epoch 23: Train Accuracy: 84.14% | Test Accuracy: 82.97% Train Loss: 0.4554 | Test Loss: 0.4825\n",
            "Epoch 24: Train Accuracy: 84.29% | Test Accuracy: 83.06% Train Loss: 0.4513 | Test Loss: 0.4797\n",
            "Epoch 25: Train Accuracy: 84.49% | Test Accuracy: 83.21% Train Loss: 0.4472 | Test Loss: 0.4760\n",
            "Epoch 26: Train Accuracy: 84.55% | Test Accuracy: 83.08% Train Loss: 0.4437 | Test Loss: 0.4761\n",
            "Epoch 27: Train Accuracy: 84.72% | Test Accuracy: 83.20% Train Loss: 0.4404 | Test Loss: 0.4710\n",
            "Epoch 28: Train Accuracy: 84.79% | Test Accuracy: 83.38% Train Loss: 0.4369 | Test Loss: 0.4685\n",
            "Epoch 29: Train Accuracy: 84.91% | Test Accuracy: 83.55% Train Loss: 0.4338 | Test Loss: 0.4652\n",
            "Epoch 30: Train Accuracy: 85.12% | Test Accuracy: 83.67% Train Loss: 0.4307 | Test Loss: 0.4616\n",
            "Batch Size: 30, Learning Rate: 0.001, Activation: relu, Final Train Accuracy: 85.12%, Final Test Accuracy: 83.67%\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "momentum = 0\n",
        "batch_size = 30\n",
        "epochs = 30\n",
        "activation = 'relu' # Can be 'relu' or 'sigmoid'\n",
        "\n",
        "# Initialize Model\n",
        "model = TwoFCLayers()\n",
        "\n",
        "# Call the training and evaluation function\n",
        "model, train_accuracy, test_accuracy = train_and_evaluate(model, batch_size, learning_rate, activation, epochs, trainset, testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3719594f",
      "metadata": {
        "id": "3719594f"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1536b2",
      "metadata": {
        "id": "cc1536b2"
      },
      "outputs": [],
      "source": [
        "# Model with 2 Fully Connected Layers, Flexible Activation Choices\n",
        "class TwoFCLayersWithFlexibleActivation(TwoFCLayers):\n",
        "    def __init__(self, activation='relu'):\n",
        "        super().__init__()  # Initialize the base class\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten 28x28 input\n",
        "        if self.activation == 'relu':\n",
        "            act_fn = torch.relu\n",
        "        elif self.activation == 'sigmoid':\n",
        "            act_fn = torch.sigmoid\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation}\")\n",
        "        x = act_fn(self.fc1(x))\n",
        "        x = act_fn(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ebc44e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ebc44e",
        "outputId": "c2a9a812-e60e-4734-f48d-1dce03b06cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Accuracy: 64.49% | Test Accuracy: 77.38% Train Loss: 0.9170 | Test Loss: 0.6033\n",
            "Epoch 2: Train Accuracy: 80.27% | Test Accuracy: 81.99% Train Loss: 0.5353 | Test Loss: 0.5042\n",
            "Epoch 3: Train Accuracy: 82.94% | Test Accuracy: 83.65% Train Loss: 0.4691 | Test Loss: 0.4567\n",
            "Epoch 4: Train Accuracy: 84.19% | Test Accuracy: 82.05% Train Loss: 0.4353 | Test Loss: 0.4819\n",
            "Epoch 5: Train Accuracy: 84.95% | Test Accuracy: 83.50% Train Loss: 0.4106 | Test Loss: 0.4393\n",
            "Epoch 6: Train Accuracy: 85.69% | Test Accuracy: 85.05% Train Loss: 0.3933 | Test Loss: 0.4089\n",
            "Epoch 7: Train Accuracy: 86.11% | Test Accuracy: 84.55% Train Loss: 0.3785 | Test Loss: 0.4414\n",
            "Epoch 8: Train Accuracy: 86.55% | Test Accuracy: 84.76% Train Loss: 0.3669 | Test Loss: 0.4138\n",
            "Epoch 9: Train Accuracy: 86.88% | Test Accuracy: 84.95% Train Loss: 0.3560 | Test Loss: 0.4041\n",
            "Epoch 10: Train Accuracy: 87.21% | Test Accuracy: 86.13% Train Loss: 0.3465 | Test Loss: 0.3841\n",
            "Epoch 11: Train Accuracy: 87.52% | Test Accuracy: 85.53% Train Loss: 0.3387 | Test Loss: 0.3957\n",
            "Epoch 12: Train Accuracy: 87.87% | Test Accuracy: 86.34% Train Loss: 0.3312 | Test Loss: 0.3819\n",
            "Epoch 13: Train Accuracy: 88.05% | Test Accuracy: 85.90% Train Loss: 0.3229 | Test Loss: 0.3874\n",
            "Epoch 14: Train Accuracy: 88.27% | Test Accuracy: 86.95% Train Loss: 0.3166 | Test Loss: 0.3644\n",
            "Epoch 15: Train Accuracy: 88.46% | Test Accuracy: 87.43% Train Loss: 0.3100 | Test Loss: 0.3553\n",
            "Epoch 16: Train Accuracy: 88.81% | Test Accuracy: 86.70% Train Loss: 0.3037 | Test Loss: 0.3683\n",
            "Epoch 17: Train Accuracy: 88.84% | Test Accuracy: 86.55% Train Loss: 0.2978 | Test Loss: 0.3776\n",
            "Epoch 18: Train Accuracy: 89.00% | Test Accuracy: 87.10% Train Loss: 0.2931 | Test Loss: 0.3597\n",
            "Epoch 19: Train Accuracy: 89.15% | Test Accuracy: 87.16% Train Loss: 0.2885 | Test Loss: 0.3557\n",
            "Epoch 20: Train Accuracy: 89.28% | Test Accuracy: 86.93% Train Loss: 0.2832 | Test Loss: 0.3617\n",
            "Batch Size: 10, Learning Rate: 0.1, Activation: sigmoid, Final Train Accuracy: 89.28%, Final Test Accuracy: 86.93%\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 10\n",
        "learning_rate = 0.1\n",
        "activation = 'sigmoid'  # Can be 'relu' or 'sigmoid'\n",
        "epochs = 20\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "model = TwoFCLayersWithFlexibleActivation(activation=activation)\n",
        "\n",
        "# Call the training and evaluation function\n",
        "model, train_accuracy, test_accuracy = train_and_evaluate(model, batch_size, learning_rate, activation, epochs, trainset, testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe51e5dc",
      "metadata": {
        "scrolled": false,
        "id": "fe51e5dc"
      },
      "outputs": [],
      "source": [
        "# Save the model for Q5\n",
        "torch.save(model.state_dict(), 'best_model_parameter.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bfe99b5",
      "metadata": {
        "id": "9bfe99b5"
      },
      "source": [
        "Q4 a Pollute the trainset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea7889b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cea7889b",
        "outputId": "885371b0-3141-4620-a2f6-04199b6375da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 has 6000 images before pollution.\n",
            "Class 1 has 6000 images before pollution.\n",
            "Class 2 has 6000 images before pollution.\n",
            "Class 3 has 6000 images before pollution.\n",
            "Class 4 has 6000 images before pollution.\n",
            "Class 5 has 6000 images before pollution.\n",
            "Class 6 has 6000 images before pollution.\n",
            "Class 7 has 6000 images before pollution.\n",
            "Class 8 has 6000 images before pollution.\n",
            "Class 9 has 6000 images before pollution.\n"
          ]
        }
      ],
      "source": [
        "# Check the balance of the trainset before the pollution\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Group the training data by class\n",
        "num_classes = 10  # Our data has 10 classes\n",
        "training_data = {class_label: [] for class_label in range(num_classes)}\n",
        "\n",
        "# Organize images by class\n",
        "for image, label in trainset:\n",
        "    training_data[label].append((image, label))  # Store as (image, label) tuples\n",
        "\n",
        "# Verify initial class sizes before pollution\n",
        "for class_label in range(num_classes):\n",
        "    print(f\"Class {class_label} has {len(training_data[class_label])} images before pollution.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab7a28b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ab7a28b",
        "outputId": "99208647-a96b-4a8e-ebe9-92c0d0ca2950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 has 6000 images after balancing.\n",
            "Class 1 has 6000 images after balancing.\n",
            "Class 2 has 6000 images after balancing.\n",
            "Class 3 has 6000 images after balancing.\n",
            "Class 4 has 6000 images after balancing.\n",
            "Class 5 has 6000 images after balancing.\n",
            "Class 6 has 6000 images after balancing.\n",
            "Class 7 has 6000 images after balancing.\n",
            "Class 8 has 6000 images after balancing.\n",
            "Class 9 has 6000 images after balancing.\n"
          ]
        }
      ],
      "source": [
        "# Pollute the dataset and check the balance of the polluted dataset\n",
        "# Deep copy the training data for pollution\n",
        "polluted_data = deepcopy(training_data)\n",
        "\n",
        "# Prepare the final balanced dataset\n",
        "balanced_data = {class_label: [] for class_label in range(num_classes)}\n",
        "\n",
        "pollution_count = 540\n",
        "for class_label in range(num_classes):\n",
        "    # Randomly sample 540 images to pollute and remove them\n",
        "    sampled_indices = np.random.choice(len(polluted_data[class_label]), pollution_count, replace=False)\n",
        "    polluted_images = [polluted_data[class_label][idx] for idx in sampled_indices]\n",
        "    remaining_images = [polluted_data[class_label][idx] for idx in range(len(polluted_data[class_label])) if idx not in sampled_indices]\n",
        "\n",
        "    # Evenly distribute polluted images across other classes\n",
        "    pollution_targets = [x for x in range(num_classes) if x != class_label]\n",
        "    target_distribution = {target: [] for target in pollution_targets}\n",
        "\n",
        "    for i, (image, _) in enumerate(polluted_images):\n",
        "        target_class = pollution_targets[i % len(pollution_targets)]\n",
        "        target_distribution[target_class].append((image, target_class))\n",
        "\n",
        "    # Add polluted images to their target classes\n",
        "    for target_class, polluted_set in target_distribution.items():\n",
        "        balanced_data[target_class].extend(polluted_set)\n",
        "\n",
        "    # Add the remaining unpolluted images (5460) to the current class\n",
        "    balanced_data[class_label].extend(remaining_images)\n",
        "\n",
        "# Flatten the balanced data into a single dataset\n",
        "flattened_polluted_data = []\n",
        "for class_label, items in balanced_data.items():\n",
        "    flattened_polluted_data.extend(items)\n",
        "\n",
        "# Verify the class sizes after balancing\n",
        "for class_label in range(num_classes):\n",
        "    count = sum(1 for _, label in flattened_polluted_data if label == class_label)\n",
        "    print(f\"Class {class_label} has {count} images after balancing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a03230",
      "metadata": {
        "id": "e4a03230"
      },
      "source": [
        "Q4 b\n",
        "\n",
        "The best set of parameters from Q3 experiemnts is: batch size 10, learning rate 0.01, momentum 0, 30 epochs, and ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3189c92e",
      "metadata": {
        "id": "3189c92e"
      },
      "outputs": [],
      "source": [
        "# For the balanced polluted data\n",
        "class PollutedDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad697029",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad697029",
        "outputId": "18d97f41-9cac-4847-ce94-75428f0ef46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Accuracy: 57.03% | Test Accuracy: 75.71% Train Loss: 1.3205 | Test Loss: 0.7065\n",
            "Epoch 2: Train Accuracy: 72.43% | Test Accuracy: 80.59% Train Loss: 0.9565 | Test Loss: 0.6124\n",
            "Epoch 3: Train Accuracy: 75.11% | Test Accuracy: 81.77% Train Loss: 0.8955 | Test Loss: 0.5938\n",
            "Epoch 4: Train Accuracy: 76.31% | Test Accuracy: 83.54% Train Loss: 0.8659 | Test Loss: 0.5204\n",
            "Epoch 5: Train Accuracy: 76.86% | Test Accuracy: 83.94% Train Loss: 0.8475 | Test Loss: 0.5138\n",
            "Epoch 6: Train Accuracy: 77.48% | Test Accuracy: 83.24% Train Loss: 0.8326 | Test Loss: 0.5198\n",
            "Epoch 7: Train Accuracy: 78.00% | Test Accuracy: 83.25% Train Loss: 0.8209 | Test Loss: 0.5457\n",
            "Epoch 8: Train Accuracy: 78.35% | Test Accuracy: 85.00% Train Loss: 0.8121 | Test Loss: 0.4771\n",
            "Epoch 9: Train Accuracy: 78.49% | Test Accuracy: 85.04% Train Loss: 0.8039 | Test Loss: 0.4815\n",
            "Epoch 10: Train Accuracy: 78.89% | Test Accuracy: 83.58% Train Loss: 0.7964 | Test Loss: 0.5080\n",
            "Epoch 11: Train Accuracy: 79.20% | Test Accuracy: 85.43% Train Loss: 0.7901 | Test Loss: 0.4734\n",
            "Epoch 12: Train Accuracy: 79.37% | Test Accuracy: 84.52% Train Loss: 0.7837 | Test Loss: 0.5043\n",
            "Epoch 13: Train Accuracy: 79.66% | Test Accuracy: 85.22% Train Loss: 0.7776 | Test Loss: 0.4716\n",
            "Epoch 14: Train Accuracy: 79.86% | Test Accuracy: 85.36% Train Loss: 0.7738 | Test Loss: 0.4676\n",
            "Epoch 15: Train Accuracy: 79.91% | Test Accuracy: 86.24% Train Loss: 0.7676 | Test Loss: 0.4612\n",
            "Epoch 16: Train Accuracy: 80.05% | Test Accuracy: 86.15% Train Loss: 0.7641 | Test Loss: 0.4580\n",
            "Epoch 17: Train Accuracy: 80.21% | Test Accuracy: 86.24% Train Loss: 0.7606 | Test Loss: 0.4653\n",
            "Epoch 18: Train Accuracy: 80.32% | Test Accuracy: 86.45% Train Loss: 0.7567 | Test Loss: 0.4622\n",
            "Epoch 19: Train Accuracy: 80.49% | Test Accuracy: 85.36% Train Loss: 0.7519 | Test Loss: 0.4650\n",
            "Epoch 20: Train Accuracy: 80.67% | Test Accuracy: 86.35% Train Loss: 0.7475 | Test Loss: 0.4471\n",
            "Batch Size: 10, Learning Rate: 0.1, Activation: sigmoid, Final Train Accuracy: 80.67%, Final Test Accuracy: 86.35%\n"
          ]
        }
      ],
      "source": [
        "polluted_trainset = PollutedDataset(flattened_polluted_data)\n",
        "\n",
        "# Train the 2FC NN model using polluted data\n",
        "# Define hyperparameters\n",
        "batch_size = 10\n",
        "learning_rate = 0.1\n",
        "activation = 'sigmoid'  # Can be 'relu' or 'sigmoid'\n",
        "epochs = 20\n",
        "\n",
        "# Initialize the model\n",
        "model = TwoFCLayersWithFlexibleActivation(activation=activation)\n",
        "\n",
        "# Train and evaluate\n",
        "model, train_accuracy, test_accuracy = train_and_evaluate(model, batch_size, learning_rate, activation, epochs, polluted_trainset, testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5acfbb85",
      "metadata": {
        "id": "5acfbb85"
      },
      "source": [
        "Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f6d704",
      "metadata": {
        "id": "06f6d704"
      },
      "source": [
        "Shift to right by 2 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a14036b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a14036b",
        "outputId": "08c87672-a69b-4679-c511-61a259befa28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy after circular shift: 49.94%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to circularly shift an image right by 2 pixels\n",
        "def circular_shift_right(image, shift=2):\n",
        "    # Convert the image to a NumPy array for easy slicing\n",
        "    image = image.numpy()\n",
        "    shifted_image = np.zeros_like(image)  # Create a placeholder for the shifted image\n",
        "    for i in range(image.shape[0]):  # Loop through rows\n",
        "        # Perform the circular shift\n",
        "        shifted_image[i] = np.concatenate((image[i, -shift:], image[i, :-shift]))\n",
        "    return torch.tensor(shifted_image)\n",
        "\n",
        "# Load the trained model with best parameter set in Q3\n",
        "model.load_state_dict(torch.load('best_model_parameter.pth'))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Evaluate the model on circularly shifted images\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        shifted_images = torch.stack([circular_shift_right(img.squeeze()) for img in images])  # Shift all batch images\n",
        "        shifted_images = shifted_images.unsqueeze(1)  # Add a channel dimension\n",
        "        outputs = model(shifted_images)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate classification accuracy\n",
        "accuracy = correct / total * 100\n",
        "print(f'Classification Accuracy after circular shift: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e5b35ec",
      "metadata": {
        "id": "2e5b35ec"
      },
      "source": [
        "Shift to down by 2 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5bfae3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b5bfae3",
        "outputId": "f3c31d3c-b906-4fd5-c43f-48d83ee7c01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy after circular shift: 67.06%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to circularly shift an image down by 2 pixels\n",
        "def circular_shift_down(image, shift=2):\n",
        "    image = image.numpy()\n",
        "    shifted_image = np.zeros_like(image)\n",
        "    shifted_image[shift:, :] = image[:-shift, :]  # Move the upper part down\n",
        "    shifted_image[:shift, :] = image[-shift:, :]  # Wrap the bottom part to the top\n",
        "    return torch.tensor(shifted_image)\n",
        "\n",
        "\n",
        "# Load the trained model with best parameter set in Q3\n",
        "model.load_state_dict(torch.load('best_model_parameter.pth'))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Evaluate the model on circularly shifted images\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        shifted_images = torch.stack([circular_shift_down(img.squeeze()) for img in images])  # Shift all batch images\n",
        "        shifted_images = shifted_images.unsqueeze(1)  # Add a channel dimension\n",
        "        outputs = model(shifted_images)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate classification accuracy\n",
        "accuracy = correct / total * 100\n",
        "print(f'Classification Accuracy after circular shift: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3563b3b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "3563b3b6",
        "outputId": "4fb6e547-6e09-45dc-f742-2aafc0a15d43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJYAAAGXCAYAAADh89pxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALlZJREFUeJzt3XuUlXW9P/DPngFmhhkGkEtclAGVi+IF80JKI+LBSPOQinTSMiErPa40KzXLEi9lC9Ii9VhWponWaelKD63CS2GpRyuPBphGacmEZBp3GGBgZvbvD39MjoDO9+swA/p6rcUf7Hne+/nuPXs/nz3vefaeQrFYLAYAAAAAJCrp7AUAAAAAsHtSLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSzxlnP55ZdHoVDIyt56661RKBRiyZIl7buoV1myZEkUCoW49dZbd9o+AHYnxxxzTBxzzDHZ2QMOOKB9F5SoUCjEJz/5yTfcbkcz5mtf+1rsvffeUVpaGmPGjNk5i/z/3syMBODNmTZtWlRVVbVp20KhEJdffnmryx5//PE46qijorKyMgqFQixYsKD9F/n/+ZmFFIoldilPP/10fPjDH47BgwdHWVlZDBo0KD70oQ/F008/3dlLA6CNthYoW/916dIlBg8eHNOmTYtly5Z1ypr+/ve/x+WXX570Ivypp56KU089NWpqaqK8vDwGDx4cxx13XFx//fXttq77778/Lr744hg3blzccsstcfXVV2etFWB38doZUV5eHoMGDYpJkybFddddF+vWrevsJSZbv359zJgxIw444ICorKyMPn36xJgxY+JTn/pU/P3vf2+XfWzZsiWmTp0aK1eujG984xsxZ86cqKmpiRtvvFH5Q6fr0tkLgK1+8pOfxGmnnRZ77LFHnHXWWTFs2LBYsmRJ3HzzzXHXXXfFf//3f8fJJ5/8htfzxS9+MS655JKsNZxxxhnxwQ9+MMrKyrLyAPzLlVdeGcOGDYtNmzbFb37zm7j11lvjkUceiT/84Q9RXl7est3999+/09fy97//Pa644ooYOnRom84KevTRR2PChAkxZMiQ+PjHPx4DBgyIpUuXxm9+85v45je/Geedd17yGrY3Y+bPnx8lJSVx8803R7du3SIi4v/+7/+S1gqwO9o6I7Zs2RL/+Mc/4le/+lVccMEF8fWvfz3mzp0bBx10UGcvsU22bNkSRx99dCxevDjOPPPMOO+882L9+vXx9NNPxw9/+MM4+eSTY9CgQcnXu3HjxujS5V8/rv/lL3+Jurq6+O53vxsf+9jHWi6/8cYbo2/fvjFt2rT2uDmQRbHELuEvf/lLnHHGGbH33nvHQw89FP369Wv52qc+9amora2NM844IxYtWhR77733dq+jvr4+Kisro0uXLq0OwilKS0ujtLQ0KwtAa8cff3wcdthhERHxsY99LPr27RszZ86MuXPnxgc+8IGW7bYWKruSr3zlK9GzZ894/PHHo1evXq2+9vLLL2dd5/ZmzMsvvxwVFRW75H0AsDO9ekZERHz+85+P+fPnx4knnhiTJ0+OP/7xj1FRUdGJK2ybe+65J37/+9/HHXfcEaeffnqrr23atCk2b96cdb2v/gVMxL9mz2tnEuwKvBWOXcLXvva12LBhQ3znO99pVSpFRPTt2zduuummqK+vj1mzZkXEvz4j4plnnonTTz89evfuHe9+97tbfe3VNm7cGOeff3707ds3evToEZMnT45ly5Zt897l7X3+xdChQ+PEE0+MRx55JI444ogoLy+PvffeO2677bZW+1i5cmVceOGFceCBB0ZVVVVUV1fH8ccfHwsXLmzHewpg91VbWxsRr/wy4dW29xlLdXV1MXny5KisrIz+/fvHpz/96bjvvvuiUCjEr371q22u+5lnnokJEyZE9+7dY/DgwS3zIiLiV7/6VRx++OERETF9+vSWt1+83lsH/vKXv8To0aO3+wK+f//+283cc889ccABB0RZWVmMHj067r333lZff+2MKRQKccstt0R9fX2rNb3RWn/729/Ge9/73ujZs2d07949xo8fH//7v/+7zXoeeeSROPzww6O8vDz22WefuOmmm3Z4ewF2Bccee2x86Utfirq6urj99ttbfW3+/PlRW1sblZWV0atXr3j/+98ff/zjH1u+vmjRoigUCjF37tyWy5544okoFArxzne+s9V1HX/88TF27NiW/7f19f72bJ1p48aN2+Zr5eXlUV1dvc3ly5Yti5NOOimqqqqiX79+ceGFF0ZTU1OrbV79c8q0adNi/PjxERExderUKBQKccwxx8TQoUPj6aefjl//+tct8+LV83T16tVxwQUXxF577RVlZWWx7777xsyZM6O5ubnVvlavXh3Tpk2Lnj17Rq9eveLMM8+M1atXv+Fth60US+wSfvrTn8bQoUNbfuh4raOPPjqGDh0aP/vZz1pdPnXq1NiwYUNcffXV8fGPf3yH1z9t2rS4/vrr44QTToiZM2dGRUVFvO9972vz+p577rk49dRT47jjjotrr702evfuHdOmTWv12U9//etf45577okTTzwxvv71r8dFF10UTz31VIwfP77d3lsNsDvbWqj07t37dberr6+PY489Nn7xi1/E+eefH5deemk8+uij8bnPfW67269atSre+973xsEHHxzXXnttjBo1Kj73uc/FvHnzIiJiv/32iyuvvDIiIj7xiU/EnDlzYs6cOXH00UfvcA01NTXxxBNPxB/+8Ic23bZHHnkkzj333PjgBz8Ys2bNik2bNsWUKVNixYoVO8zMmTMnamtro6ysrGVNb7TW+fPnx9FHHx1r166NGTNmxNVXXx2rV6+OY489Nn73u9+1XPdTTz0V73nPe+Lll1+Oyy+/PKZPnx4zZsyIu+++u023B6CznHHGGRHR+m3Sv/jFL2LSpEktx7TPfOYz8eijj8a4ceNaZssBBxwQvXr1ioceeqgl9/DDD0dJSUksXLgw1q5dGxERzc3N8eijj24zA9ryen97ampqIiLitttui2Kx+Ia3r6mpKSZNmhR9+vSJa665JsaPHx/XXnttfOc739lh5uyzz44vfOELERFx/vnnx5w5c+LSSy+N2bNnx5577hmjRo1qmReXXnppRERs2LAhxo8fH7fffnt85CMfieuuuy7GjRsXn//85+Mzn/lMy3UXi8V4//vfH3PmzIkPf/jD8eUvfzleeOGFOPPMM9/wtkCLInSy1atXFyOi+P73v/91t5s8eXIxIopr164tzpgxoxgRxdNOO22b7bZ+basnnniiGBHFCy64oNV206ZNK0ZEccaMGS2X3XLLLcWIKD7//PMtl9XU1BQjovjQQw+1XPbyyy8Xy8rKip/97GdbLtu0aVOxqamp1T6ef/75YllZWfHKK69sdVlEFG+55ZbXvb0Au6utx9Jf/OIXxX/+85/FpUuXFu+6665iv379imVlZcWlS5e22n78+PHF8ePHt/z/2muvLUZE8Z577mm5bOPGjcVRo0YVI6L44IMPtspGRPG2225ruayhoaE4YMCA4pQpU1oue/zxx5OOvffff3+xtLS0WFpaWjzyyCOLF198cfG+++4rbt68eZttI6LYrVu34nPPPddy2cKFC4sRUbz++uu3uV9ePWPOPPPMYmVlZavr29Fam5ubi8OHDy9OmjSp2Nzc3HL5hg0bisOGDSsed9xxLZeddNJJxfLy8mJdXV3LZc8880yxtLS06OUf0Jm2Hgsff/zxHW7Ts2fP4iGHHNLy/zFjxhT79+9fXLFiRctlCxcuLJaUlBQ/8pGPtFz2vve9r3jEEUe0/P+UU04pnnLKKcXS0tLivHnzisVisfjkk08WI6L4P//zPy3btfX1/vZs2LChOHLkyGJEFGtqaorTpk0r3nzzzcWXXnppm23PPPPMYkS0+tmgWCwWDznkkOKhhx7a6rLX/pzy4IMPFiOieOedd7babvTo0a1m6FZXXXVVsbKysvjnP/+51eWXXHJJsbS0tPi3v/2tWCwWi/fcc08xIoqzZs1q2aaxsbFYW1vrZxbazBlLdLqtf/mhR48er7vd1q9v/W1DRMQ555zzhte/9a0I5557bqvLUz54df/99291NlW/fv1i5MiR8de//rXlsrKysigpeeUp1dTUFCtWrIiqqqoYOXJkPPnkk23eF8BbxcSJE6Nfv36x1157xamnnhqVlZUxd+7c2HPPPV83d++998bgwYNj8uTJLZeVl5fv8MzUqqqq+PCHP9zy/27dusURRxzR6hid6rjjjovHHnssJk+eHAsXLoxZs2bFpEmTYvDgwa3eZrHVxIkTY5999mn5/0EHHRTV1dVvag2vtWDBgnj22Wfj9NNPjxUrVsTy5ctj+fLlUV9fH//2b/8WDz30UDQ3N0dTU1Pcd999cdJJJ8WQIUNa8vvtt19MmjSp3dYDsLNUVVW1/Izw4osvxoIFC2LatGmxxx57tGxz0EEHxXHHHRc///nPWy6rra2NJ598Murr6yPilbNJTzjhhBgzZkw8/PDDEfHKWUyFQqHlYzS2asvr/e2pqKiI3/72t3HRRRdFxCtvez7rrLNi4MCBcd5550VDQ8M2mdf+DFNbW9uu8yIi4s4774za2tro3bt3y7xYvnx5TJw4MZqamlrO7Pr5z38eXbp0if/8z/9syZaWlmb9kQrevnx4N51ua2H0Rn9adHsF1LBhw97w+uvq6qKkpGSbbffdd982r/HVL8y36t27d6xatarl/83NzfHNb34zbrzxxnj++edbvU+6T58+bd4XwFvFf/3Xf8WIESNizZo18f3vfz8eeuihNv3Vzbq6uthnn322+by8HR2399xzz2227d27dyxatCh/8RFx+OGHx09+8pPYvHlzLFy4MO6+++74xje+EaeeemosWLAg9t9//5Zt2zIn3qxnn302IuJ1356wZs2aaGhoiI0bN8bw4cO3+frIkSNb/RAGsCtav359y+fZ1dXVRcQrx6/X2m+//eK+++5r+SM+tbW10djYGI899ljstdde8fLLL0dtbW08/fTTrYql/fffv1VJFfHmjuM9e/aMWbNmxaxZs6Kuri5++ctfxjXXXBM33HBD9OzZM7785S+3bFteXr7NZ8q297yIeGVmLFq0aJt9bbX1w8Dr6upi4MCBUVVV1err27u/YUcUS3S6nj17xsCBA9/wB4BFixbF4MGDW30AXkf9pYgd/aW44qveR3311VfHl770pfjoRz8aV111Veyxxx5RUlISF1xwwTYfkAfwdnDEEUe0/MWfk046Kd797nfH6aefHn/605+2eQH7ZrTlGP1mdOvWLQ4//PA4/PDDY8SIETF9+vS48847Y8aMGR22hohomSVf+9rXYsyYMdvdpqqqaru/HQfYXbzwwguxZs2apF8Cb3XYYYdFeXl5PPTQQzFkyJDo379/jBgxImpra+PGG2+MhoaGePjhh+Pkk0/eJttex/Gampr46Ec/GieffHLsvffecccdd7QqljrqL1A3NzfHcccdFxdffPF2vz5ixIgOWQdvD4oldgknnnhifPe7341HHnlkm9NSI175zcKSJUvi7LPPTr7umpqaaG5ujueff77Vb2+fe+65N7Xm17rrrrtiwoQJcfPNN7e6fPXq1dG3b9923RfA7qa0tDS++tWvxoQJE+KGG26ISy65ZIfb1tTUxDPPPBPFYrHVmUhv5rj92jOacm0tyl588cV2ub7t2dFat77Vrrq6OiZOnLjDfL9+/aKioqLlDKdX+9Of/tQ+iwTYSebMmRMR0fLW3a0fjr2949fixYujb9++UVlZGRH/eiv0ww8/HEOGDGl5a1ttbW00NDTEHXfcES+99NLr/vGG9tK7d+/YZ5992vxHIHK93sxYv379686LiFfu31/+8pexfv36Vr/0MS9I4TOW2CVcdNFFUVFREWefffY2f0Fn5cqVcc4550T37t1b3rucYutQuvHGG1tdfv311+cveDtKS0u3+Y3GnXfeGcuWLWvX/QDsro455pg44ogjYvbs2bFp06Ydbjdp0qRYtmxZq88y2rRpU3z3u9/N3vfWHzra+ueTH3zwwe3+lnrr28h25lsEdrTWQw89NPbZZ5+45pprYv369dvk/vnPf0bEK/No0qRJcc8998Tf/va3lq//8Y9/jPvuu2+nrRvgzZo/f35cddVVMWzYsPjQhz4UEREDBw6MMWPGxA9+8INWx8U//OEPcf/998cJJ5zQ6jpqa2vjt7/9bTz44IMtxVLfvn1jv/32i5kzZ7Zs014WLlwYy5cv3+byurq6eOaZZ3b6W8oqKyu3O9s+8IEPxGOPPbbd4/7q1aujsbExIiJOOOGEaGxsjG9961stX29qamr3n5V4a3PGEruE4cOHxw9+8IP40Ic+FAceeGCcddZZMWzYsFiyZEncfPPNsXz58vjRj37U6oNR2+rQQw+NKVOmxOzZs2PFihXxrne9K37961/Hn//854hov99in3jiiXHllVfG9OnT46ijjoqnnnoq7rjjjth7773b5foB3gouuuiimDp1atx66607/AMMZ599dtxwww1x2mmnxac+9akYOHBg3HHHHVFeXh4RecftffbZJ3r16hXf/va3o0ePHlFZWRljx47d4Wf1nXfeebFhw4Y4+eSTY9SoUbF58+Z49NFH48c//nEMHTo0pk+fnryG9ljr9773vTj++ONj9OjRMX369Bg8eHAsW7YsHnzwwaiuro6f/vSnERFxxRVXxL333hu1tbVx7rnnRmNjY1x//fUxevToN/3ZUwDtYd68ebF48eJobGyMl156KebPnx8PPPBA1NTUxNy5c1uO+RGvvAX4+OOPjyOPPDLOOuus2LhxY1x//fXRs2fPuPzyy1tdb21tbXzlK1+JpUuXtiqQjj766Ljpppti6NChb/hHJFI88MADMWPGjJg8eXK8613viqqqqvjrX/8a3//+96OhoWGb9bW3Qw89NL71rW/Fl7/85dh3332jf//+ceyxx8ZFF10Uc+fOjRNPPDGmTZsWhx56aNTX18dTTz0Vd911VyxZsiT69u0b//7v/x7jxo2LSy65JJYsWRL7779//OQnP4k1a9bs1HXz1qJYYpcxderUGDVqVHz1q19tKZP69OkTEyZMiC984QtxwAEHZF/3bbfdFgMGDIgf/ehHcffdd8fEiRPjxz/+cYwcObLV0HozvvCFL0R9fX388Ic/jB//+Mfxzne+M372s5+97ts9AN5uTjnllJazbj7+8Y9v97MmqqqqYv78+XHeeefFN7/5zaiqqoqPfOQjcdRRR8WUKVOyjttdu3aNH/zgB/H5z38+zjnnnGhsbIxbbrllh8XSNddcE3feeWf8/Oc/j+985zuxefPmGDJkSJx77rnxxS9+MXr16pW8hvZY6zHHHBOPPfZYXHXVVXHDDTfE+vXrY8CAATF27NhWbxc/6KCD4r777ovPfOYzcdlll8Wee+4ZV1xxRbz44ouKJWCXcNlll0XEK29f22OPPeLAAw+M2bNnx/Tp07f5a9ETJ06Me++9N2bMmBGXXXZZdO3aNcaPHx8zZ87c5jh+1FFHRWlpaXTv3j0OPvjglstra2vjpptuatezlSIipkyZEuvWrYv7778/5s+fHytXrozevXvHEUccEZ/97GdjwoQJ7bq/17rsssuirq4uZs2aFevWrYvx48fHscceG927d49f//rXcfXVV8edd94Zt912W1RXV8eIESPiiiuuiJ49e0ZERElJScydOzcuuOCCuP3226NQKMTkyZPj2muvjUMOOWSnrp23jkKxPT9VEnYjCxYsiEMOOSRuv/32llNtAdh1zZ49Oz796U/HCy+8EIMHD+7s5QAAED5jibeJjRs3bnPZ7Nmzo6SkpEM+vA+ANK89bm/atCluuummGD58uFIJAGAX4q1wvC3MmjUrnnjiiZgwYUJ06dIl5s2bF/PmzYtPfOITsddee3X28gB4jVNOOSWGDBkSY8aMiTVr1sTtt98eixcvjjvuuKOzlwYAwKt4KxxvCw888EBcccUV8cwzz8T69etjyJAhccYZZ8Sll14aXbroVwF2NbNnz47vfe97sWTJkmhqaor9998/Lr744viP//iPzl4aAACvolgCAAAAIIvPWAIAAAAgi2IJAAAAgCyKJQAAAACytPlTiwuFws5cBwDtqLM+Ps+sANh9mBUAvJG2zApnLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAli6dvQCg85WWliZnmpubkzPFYjE5k6OsrCw509DQkJzZd999kzPPPfdccgbg7cRM6riZBADtwRlLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWbp09gKgvRQKhQ7JNDc3J2ciIgYPHpycOfLII5Mz8+bNS87U19cnZ3ZlDQ0NHbKfKVOmJGdmzpy5E1YC7Gpy5ktuLmcumUkdZ1eeSQDQHpyxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkKVLZy8AOlNzc3OH7au2tjY5M3bs2OTMoEGDkjPXXXddcmZX1r9//+TMpEmTkjNr165NzgC8no6aS2ZSxzGTgLeT0tLS5EzO7CsWi8mZHGVlZcmZhoaG5My+++6bnHnuueeSMzuLM5YAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACydOnsBUB7KS0tTc40NjYmZw477LDkTETEfvvtl5x56aWXkjPDhw9Pztx9993JmZUrVyZnKioqkjN1dXXJmT59+iRnqqurkzMvvPBCcgZ4e8iZSREdN5fMJDMJ2LFCodAhmebm5uRMRMTgwYOTM0ceeWRyZt68ecmZ+vr65MyurKGhoUP2M2XKlOTMzJkzd8JK8jhjCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIEuXzl4AbE9JSXrn2djYmJyprKxMzkydOjU5ExHR0NCQnCkvL0/O9OjRIzlTKBSSMznfo5z9jB49OjmzdOnS5MyqVauSM126OITC20FHzaSIjptLZpKZBLSv5ubmDttXbW1tcmbs2LHJmUGDBiVnrrvuuuTMrqx///7JmUmTJiVn1q5dm5zZlThjCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIEuXzl7AW12hUEjOFIvF5ExJSXpHmLOfnExpaWlypqmpKTmT45xzzknO/OMf/8ja16ZNm5IzQ4cOTc6Ul5cnZ1566aXkTM73tbm5OTlTX1+fnNm8eXNyprq6OjlTVlaWnKmsrEzO5NwHneWtfvt2d2bSrj2TIjpuLplJZhKwYznHlMbGxuTMYYcdlpyJiNhvv/2SMznH1uHDhydn7r777uTMypUrkzMVFRXJmbq6uuRMnz59kjM5x/AXXnghObMrccYSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAli6dvYDOUigUkjPFYrFDMjmam5s7ZD+lpaXJmaampp2wkm2ddtppyZkBAwYkZ5588snkTERE165dkzO9evVKzqxYsSI5s3LlyuRM3759kzM9evRIzuQ85nKUlKT37N27d0/ODB8+PDmzYMGC5Exneavfvp3FTMrzVptJER03l8wkMwneLnKeT42NjcmZysrK5MzUqVOTMxERDQ0NyZny8vLkTM5xMuc1Tc73KGc/o0ePTs4sXbo0ObNq1arkTJcuu3c144wlAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALF06ewGdpVgsdsh+SkrSu7ucTFNTU3Im5z7I2U+O6dOnJ2dGjhyZnFm6dGlypm/fvsmZiIhCoZCcqaioSM4sW7YsOdOjR4/kTHNzc3Jmw4YNyZny8vLkTM593VHHhEmTJiVnFixY0P4L2Une6rdvZzGTzKStOmoumUlmErufjnos5Rz3c/aTkyktLU3OdNSsOOecc5Iz//jHP7L2tWnTpuTM0KFDkzM5x7yXXnopOZPzfc057tfX1ydnNm/enJyprq5OzpSVlSVnKisrkzM590FbOGMJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCxdOnsBr1VS0jFdV7FYTM4UCoXkTHNzc4dkOsqgQYOSM6ecckpypqKiIjnz7LPPJmeqqqqSM2VlZcmZiIg+ffokZzZv3pycyXlsd+/ePTmTo6mpKTnT0NDQIfupr69PzuQ8V8eNG5ec2Z281W6fmWQmRXTcTIrouLlkJplJtJ+c43HOcyMnk6OjHkulpaXJmZznU47TTjstOTNgwIDkzJNPPpmciYjo2rVrcqZXr17JmRUrViRnVq5cmZzp27dvcqZHjx7JmZzHXI6c1485s2/48OHJmQULFiRn2sIZSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFm6tHXD0tLS5CtvampKzjQ3NydnOkqxWOyQ/fTr1y85U1NTk5wZNWpUcmbgwIHJmc2bNydn1q5dm5zp1atXcqa6ujo507Vr1+RMRERZWVlyJuf5kPNYyLlNq1evTs5s2bIlOZNzH5SUpHfmGzduTM7kHBfXrVuXnBk9enRyprN01O1bvHhxcsZMymMmddxMiui4uWQmmUm0n446Huc8lnIyOfMy5z7I2U+O6dOnJ2dGjhyZnFm6dGlypm/fvsmZiIhCoZCcqaioSM4sW7YsOdOjR4/kTM6xdcOGDcmZ8vLy5EzOfd1Rx4RJkyYlZxYsWND+CwlnLAEAAACQSbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGTp0tYNm5qaduY6WrzjHe9IztTU1CRnKisrOyRTUVGRnBk2bFhypnv37smZLVu2JGfWr1+fnCkpSe8ve/bsmZzJua8bGxuTMzn3dUTEhg0bkjMNDQ3JmW7duiVnXnzxxeRMzvco575btWpVcqaqqio507t37+RMfX19cmbAgAHJmT59+iRnOktH3T4zyUyKeOvNpIiOm0tmkpn0dpDzfM9RLBaTM4VCITnT3NzcIZmOMmjQoOTMKaeckpzJOR4/++yzyZmc53pZWVlyJiLvtdPmzZuTMzmP7dyflVLlvBbMmWM5+8k5Huc8V8eNG5ec2VmcsQQAAABAFsUSAAAAAFkUSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJCly8688okTJyZnBg0alJzZsmVLcqZ///7JmZKS9B6uubk5OZNze9atW5ecqaqqSs4MGDAgOVMoFJIzZWVlyZlVq1YlZ3K+pzn3W0REaWlpcqa+vj45k/NYWLNmTXIm5znUUXIeCznP1YqKiuRMt27dkjONjY3Jmc6yK98+M8lMiti1Z1JEx80lM6nj7MozqbPkPP6ampqSMzn3Y0cpFosdsp9+/folZ2pqapIzo0aNSs4MHDgwObN58+bkzNq1a5MzvXr1Ss5UV1cnZ7p27ZqcicibSznPh5zHQs5tWr16dXIm5/VJzn2QM5c3btyYnMk5LubM2NGjRydn2sIZSwAAAABkUSwBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFm6tHXD97znPclXftZZZyVnFi9enJx58cUXkzNr165NzpSWliZnNm/e3CH7ybFu3brkTLdu3ZIzTU1NyZnq6urkTKFQSM5UVFQkZ5qbm5MzERFdu3ZNzgwYMCA58453vCM5M3r06ORMzu3pqMd2fX19cqZ79+7JmU2bNiVnctb28ssvJ2c6S0fdPjPJTIp4682kiI6bS2aSmdSZcp6HOXIefzU1NcmZysrKDsnkHB+GDRuWnMl5/G3ZsiU5s379+uRMSUn6eRE9e/ZMzuTc142NjcmZnPs6ImLDhg3JmYaGhuRMzpzNeR2U8z3Kue9WrVqVnKmqqkrO9O7dOzmTMyty5nKfPn2SM23hjCUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsXdq64e9+97vkK3/Xu96VnDnwwAOTM+PGjUvO5GhsbEzOrFu3LjmzcuXKDsmsWbMmOdOtW7fkTKFQSM706dMnOTNy5MjkTPfu3ZMz1dXVyZmIiGKxmJw5+OCDkzOLFi1KzixZsiQ5M3HixORMWVlZcibnfsuR8/xetmxZcmbt2rXJmaqqquRMZ+nfv39yJuf2mUlmUsRbbyZFdNxcMpPMpN1Nzvd40KBByZktW7YkZ3JmX0lJ+u/3m5ubkzM5tydnVuTM8gEDBiRnco7hOc/1VatWJWdyvqe5r/FKS0uTM/X19cmZnMdCzjzPeQ51lJzHQs5ztaKiIjmT8zooZ760hTOWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAshSKxWKxTRsWCjt7LdmqqqqSM2PHjk3OjBgxIjlz1FFHJWf69++fnKmurk7OVFZWJmdyHgdtfIi10tzcnJxZuXJlcmbx4sXJmQceeCA5ExExb9685MymTZuy9tUR5s6dm5wZMmRIcmb58uXJmXXr1nVIprGxMTnT0NCQnLnwwguTM+vXr0/OtIdvf/vbyZmc21dfX5+c6ShmkpkUkTeTIjpuLplJZlJExPTp05Mz7WHSpEnJmbPOOis5k/N8evHFF5MzObO9tLQ0ObN58+YO2U+Orl27Jme6deuWnGlqakrO5MyknPlSUVGRnOnbt29yJiKirKwsOZMzZ9/xjnckZ3LkPH466rGd85qze/fuyZmcGbtly5bkzCc/+cnkzLPPPvuG2zhjCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIEuhWCwW27RhobCz1wJAO2njob3dmRUAu4/OmhW9e/dOzpx//vnJmQMPPDA5k7O2HI2NjcmZdevWJWdWrlzZIZk1a9YkZ7p165acyXmd0adPn+TMyJEjkzPdu3dPzlRXVydnIvKeuwcffHByZtGiRcmZJUuWJGcmTpyYnCkrK0vOdNQxL+f5vWzZsuTM2rVrkzMf/ehHkzO///3v33AbZywBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJBFsQQAAABAFsUSAAAAAFkUSwAAAABkKRSLxWKbNiwUdvZaAGgnbTy0tzuzAmD3YVZsq6qqKjkzduzY5MyIESOSM0cddVRypn///smZ6urq5ExlZWVyJudxkPOYbW5uTs6sXLkyObN48eLkzAMPPJCciYiYN29ecmbTpk1Z++oIc+fOTc4MGTIkObN8+fLkzLp16zok09jYmJxpaGhIzlx44YXJmfXr17/hNs5YAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyFIoFovFNm1YKOzstQDQTtp4aG93ZgXA7sOsAOCNtGVWOGMJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyKJYAgAAACCLYgkAAACALIolAAAAALIolgAAAADIolgCAAAAIItiCQAAAIAsiiUAAAAAsiiWAAAAAMiiWAIAAAAgi2IJAAAAgCyKJQAAAACyKJYAAAAAyFIoFovFzl4EAAAAALsfZywBAAAAkEWxBAAAAEAWxRIAAAAAWRRLAAAAAGRRLAEAAACQRbEEAAAAQBbFEgAAAABZFEsAAAAAZFEsAQAAAJDl/wGjFu2iqlXFQwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Double check if images shifted correctly\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the first image and label from the test loader\n",
        "images, labels = next(iter(testloader))\n",
        "original_image = images[0].squeeze()  # Get the first image and remove channel dimension\n",
        "\n",
        "# Apply the shift functions\n",
        "right_shifted_image = circular_shift_right(original_image, shift=2)\n",
        "down_shifted_image = circular_shift_down(original_image, shift=2)\n",
        "\n",
        "# Define a helper function to visualize the images\n",
        "def show_images(original, right_shifted, down_shifted):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    titles = [\"Original\", \"Right Shifted\", \"Down Shifted\"]\n",
        "    images = [original, right_shifted, down_shifted]\n",
        "\n",
        "    for ax, img, title in zip(axes, images, titles):\n",
        "        ax.imshow(img.numpy(), cmap='gray')\n",
        "        ax.set_title(title)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the original and shifted images\n",
        "show_images(original_image, right_shifted_image, down_shifted_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414f3a63",
      "metadata": {
        "id": "414f3a63"
      },
      "source": [
        "Q6\n",
        "Took this photo with iPhone 13, and switched from .HEIC to .JPG using a converter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074de7cc",
      "metadata": {
        "id": "074de7cc"
      },
      "source": [
        "![shirt.jpg](attachment:shirt.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fa98c69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "8fa98c69",
        "outputId": "6c44c635-8616-4a1b-f8ab-eb921348022f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 6\n",
            "Class Probabilities: [0.02345973253250122, 0.0007377225556410849, 0.35974928736686707, 0.004515283741056919, 0.034889448434114456, 2.1722609744756483e-05, 0.5473917126655579, 8.415467078748406e-08, 0.029218802228569984, 1.6260595657513477e-05]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Load the saved model\n",
        "# model = TwoFCLayersWithFlexibleActivation(activation='relu')\n",
        "model.load_state_dict(torch.load('best_model_parameter.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),                    # Convert to grayscale\n",
        "    transforms.Resize((28, 28)),               # Resize to 28x28\n",
        "    transforms.ToTensor(),                     # Convert to tensor and normalize\n",
        "])\n",
        "\n",
        "# Load and process the image\n",
        "image_path = 'shirt.jpg'  # Replace with your image path\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Convert the image to grayscale and invert colors\n",
        "# Origianlly the image I took has white background and pants color is black,\n",
        "# but I found that the training dataset's examples are having black background and white garment.\n",
        "image = ImageOps.grayscale(image)  # Convert to grayscale\n",
        "image = ImageOps.invert(image)     # Invert colors\n",
        "\n",
        "\n",
        "# Apply transformations\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Visualize the preprocessed image\n",
        "processed_image = transforms.ToPILImage()(image_tensor.squeeze(0))  # Convert tensor to PIL Image\n",
        "plt.imshow(processed_image, cmap=\"gray\")  # Display as grayscale image\n",
        "plt.title(\"Processed Grayscale Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Classify the image\n",
        "with torch.no_grad():\n",
        "    outputs = model(image_tensor)\n",
        "    probabilities = torch.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "print(f\"Class Probabilities: {probabilities.squeeze().tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "notebook_filename = '/content/drive/My Drive/Colab Notebooks/CS540 Programming Assignment #1 - Saeah Go.ipynb'\n",
        "\n",
        "# Create a .tar.gz archive\n",
        "with tarfile.open('saeah_go_hw1.tar.gz', 'w:gz') as tar:\n",
        "    tar.add(notebook_filename)\n",
        "\n",
        "# Optionally, you can move the created archive to a specific directory\n",
        "shutil.move('saeah_go_hw1.tar.gz', '/content/drive/My Drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qbdVOdXSn-OX",
        "outputId": "c28d47e6-f32b-4f1e-a4de-aeedb62d5a63"
      },
      "id": "qbdVOdXSn-OX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/saeah_go_hw1.tar.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/My Drive/Colab Notebooks/'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwYTLwUOozW6",
        "outputId": "6273c0d8-8bbd-416b-a39c-6f77207f68af"
      },
      "id": "KwYTLwUOozW6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Numpy_tutorial.ipynb', 'MTH371 - HW 1 Draft 1', 'HW2_raw01312022.ipynb', 'HW2_raw.ipynb', 'Networkx_walkthrough_new(1)-1.ipynb', 'MTH371 Saeah Go HW #2.ipynb', '(Python) Water Quality - open shapefile.ipynb', '(R) Water Quality.ipynb', 'Copy of hw4_with_guide.ipynb', 'CS445 HW#1 Q11 (Perceptron with MNIST).ipynb', 'Copy of CS445 HW#1 Q11 (Perceptron with MNIST).ipynb', 'Correct Ver CS445 HW#1 Q11 (Perceptron with MNIST).ipynb', 'Draft 3 CS445 Programming 1-incorrect.ipynb', 'Draft 2 CS445 Programming 1.ipynb', 'Draft 4 CS445 Programming 1.ipynb', 'Draft 5 CS445 Programming 1 - For Experiment 3.ipynb', 'Copy of Program#1 Yifan.ipynb', 'Gradient Descent (GD) Algorithm.ipynb', 'Draft 6 CS445 Programming 1.ipynb', 'Untitled0.ipynb', 'Programming 2 Draft1.ipynb', 'Hw1_notebook (1).ipynb', 'Spectral Clustering, K-means Clustering.ipynb', \"Implementation of Luby's Algorithm.ipynb\", 'Copy of K-Means Clustering (Program 3).ipynb', 'K-Means Clustering (Program 3).ipynb', 'Untitled (2)', 'Hw1_notebook.ipynb', 'Final Ver CS445 HW#1 Q11 (Perceptron with MNIST).ipynb', 'McKinsey Technical Interview Prep.ipynb', 'CREC 2022 All Staff Training Survey Visualization.ipynb', 'Copy of CREC 2022 All Staff Training Survey Visualization.ipynb', 'Untitled (1)', 'CS441 Programming1 Draft2.ipynb', 'CS441 Programming1 Draft3.ipynb', 'CS441 Programming1 Draft4.ipynb', 'CS441 Programming1 Draft5.ipynb', 'CS441 HW #2 Gradient Descent (GD) Algorithm.ipynb', 'NCHA Survey.ipynb', 'Final version of CS441 Programming 2.ipynb', 'CS441 HW1 Q10.ipynb', 'CS441 Programming 3 Draft.ipynb', 'CS441 Programming 3.ipynb', 'Test 1 kid of TSP Genetic Algorithm.ipynb', 'CS441 Group Project Greedy Search.ipynb', 'CS441 Group Project Genetic Algorithm.ipynb', 'Untitled1.ipynb', 'BTA419 Textbook.ipynb', 'BTA419 Midterm.ipynb', 'Copy of Yifan CS441 Programming#2.ipynb', 'Yifan Test TSP Genetic Algorithm.ipynb', 'Copy of CS445_GroupProject_ModelComparisons.ipynb', 'saeah-go-bta419-w23.ipynb', 'saeahgo-bta419-w23 draft2.ipynb', 'huayu-wu-bta-419-individual-youtube-video-analysis .ipynb', 'CH2-Auto.ipynb', 'HW1.ipynb', 'CH5-Housing.ipynb', 'CH6-BreastCancer.ipynb', 'HW2-3.ipynb', 'Untitled', 'CH7-Class-Gradient.ipynb', 'CH7-GradDecent.ipynb', 'Untitled2.ipynb', 'CH8-SVM.ipynb', 'HW3-1.ipynb', 'CS445 Programming 1.ipynb', 'CS545 HW4 Q5.ipynb', 'ML Final Exam.ipynb', 'CS540 Deep Learning Final Project.ipynb', 'references.bib', 'Saeah Problem Set 0.pdf', 'Saeah Problem Set 0.ipynb', 'Problem Set Image Denoise - Hints.ipynb', 'Copy of CS540 Programming Assignment #1 Experiment.ipynb', 'CS540 Programming Assignment #1 Experiment.ipynb', 'Another copy of CS540 Programming Assignment #1 Experiment.ipynb', 'Saeah Problem Set 1.pdf', 'CS540 Assignment 1 Training Test Accuracy.ipynb', 'CS540 Programming Assignment #1 -Q3 exp 2.ipynb', 'CS540 Programming Assignment #1 -Q3 exp 1.ipynb', 'Saeah Problem Set 1.ipynb', 'CS540 Programming Assignment #1 -Q3 exp 3.ipynb', 'CS540 Programming Assignment #1 - Saeah Go.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTG7KIvBo4eE",
        "outputId": "645a82ca-6000-45b9-9285-d0c1649f5fc3"
      },
      "id": "vTG7KIvBo4eE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}